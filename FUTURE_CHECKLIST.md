* [ ] Switch submodule URLs in .gitmodules from SSH to HTTPS to simplify CI clones without SSH keys (public submodules .cursor/rules and scripts), smallest change is editing .gitmodules and running git submodule sync; scope repository hygiene; low risk; DoD includes actions/checkout with submodules enabled succeeding in a new CI workflow, tests unchanged and green with no coverage regression, all quality gates green, peer review completed, verification by observing CI clone success without extra SSH setup and local git submodule update --init works, rollback by reverting the .gitmodules change and syncing.
* [ ] Strengthen the Makefile test target to run go test -race -cover ./... and write a coverage profile under bin/coverage.out so local testing matches planned CI gates, smallest change is editing the Makefile test recipe only; scope Makefile; low risk; DoD includes running make test from a clean clone succeeds with race detector enabled and coverage file produced, tests otherwise unchanged and green with no coverage regression, all quality gates green with no new findings, peer review completed, verification by observing race-enabled run and generated coverage file, rollback by reverting the Makefile edit.
* [ ] Add a make vuln target that installs and runs govulncheck ./... and wire it into CI after unit tests to fail builds on known vulnerabilities, smallest change is adding the target in the Makefile and a CI step once workflows exist; scope security scanning; low risk; DoD includes make vuln passing locally on a clean tree, CI green with the new step and no new findings, tests unchanged and green with no coverage regression, all gates green, peer review completed, verification by introducing a known vulnerable transient dependency in a branch to see CI fail then removing it restores green, rollback by reverting the Makefile and CI edits.
* [ ] Add secret detection with gitleaks via a make secrets target and a CI step using the official action with a minimal .gitleaks.toml allowlist to reduce false positives, smallest change is adding the config, target and CI step; scope security hygiene; low risk; DoD includes make secrets passing locally on a clean tree, CI green with no new leaks, tests unchanged and green with no coverage regression, all gates green, peer review completed, verification by committing a fake test secret in a branch to observe CI fail then removing it restores green, rollback by reverting the config and CI step.
* [ ] Standardize all Bash scripts under scripts to use env bash shebang and strict mode set -euo pipefail and add a make shellcheck target with a minimal configuration plus a CI step to run it, because several scripts currently lack pipefail or only set -u which weakens detection of failures; smallest change is editing script headers, adding one Makefile target, and a short workflow step; scope scripts, Makefile, CI; low risk; DoD includes an initial failing run then passing with zero shellcheck warnings, tests unchanged and green with no coverage regression, all quality gates green, peer review completed, verification by running shellcheck locally and observing CI green, rollback by reverting the script, Makefile, and workflow edits.
* [ ] CI smoke job for tools — workflow builds tools, runs each binary with sample stdin, and runs an agent loop against a fake API; no external network dependence; DoD: green in PRs, artifacts attached, linked to issue.
* [ ] Add docs/operations/ci-quality-gates.md mapping each quality gate to exact local commands and expected outputs for lint vet fmt unit and integration tests and coverage including a note on fixing golangci-lint not found by adding the Go bin directory to PATH, smallest change is one runbook file and a link from README Tests, low risk, DoD includes commands verified from a clean clone tests unchanged and green with no coverage regression all gates green in CI peer review completed verification by following steps locally rollback by reverting the doc and links, traceability https://github.com/hyperifyio/goagent/issues/213.
* [ ] Document the release process in docs/releasing.md including tagging artifact naming checksums and verification and rollback guidance aligned with the planned release workflow, smallest change is a single page and links from README and the future release workflow, scope documentation, low risk, DoD includes dry run steps validated locally without publishing tests unchanged and green all quality gates green peer review completed verification by executing the documented commands in dry run rollback by removing the doc and links, traceability https://github.com/hyperifyio/goagent/issues/214.
* [ ] Add release workflow for static binaries and checksums: `.github/workflows/release.yml` triggered on tags like `v*`; build `agentcli` for `linux,darwin,windows` × `amd64,arm64` with `CGO_ENABLED=0`; name outputs `agentcli_<os>_<arch>` (Windows `.exe`); generate `SHA256SUMS` and `SHA256SUMS.sig` (optional GPG); create GitHub Release and upload artifacts and checksums; document in README how to download and verify.
* [ ] Add a make sbom target that uses syft (or cyclonedx-gomod as a fallback if syft is unavailable) to produce a CycloneDX SBOM at reports/sbom.json from the current module and wire it into the release workflow to upload as an asset, because the repo currently lacks an SBOM which weakens supply-chain visibility; smallest change is adding one Makefile target and a short CI step with a docs sentence; scope Makefile and CI; low risk; DoD includes failing first when the tool is missing then passing with deterministic output on a clean clone, tests unchanged and green with no coverage regression, all quality gates green (vet, format, golangci-lint, static analysis, security and secret scans) with no new findings, backward compatibility preserved, peer review completed, verification by running make sbom locally and seeing reports/sbom.json and by confirming the asset on a tagged release, rollback by reverting the Makefile and workflow edits.
* [ ] Tag and publish `v0.1.0` once CI is green and docs/tests are complete: ensure `README.md` has usage, examples, and limitations (no streaming, sequential tool calls only); ADR-0001 and sequence diagram present; unit and integration tests passing; create annotated tag `git tag -a v0.1.0 -m "MVP non-interactive agent CLI with OpenAI-compatible tools"` and `git push --tags`.
* [ ] Add GitHub Dependabot at .github/dependabot.yml to update Go modules weekly and GitHub Actions monthly so dependencies and CI actions stay current with minimal noise; smallest change is committing a single dependabot.yml file; scope repository hygiene; low risk and independent; DoD includes Dependabot PRs opening on schedule with passing CI and no coverage regression, all quality gates green (vet, format, lint, security and secret detection) with no new findings, peer review completed; verification by observing the first PRs or running a local preview, rollback by removing the configuration file.
* [ ] CLI errors: when required flags (e.g., `-prompt`) are missing, print concise error followed by the usage synopsis and exit with code 2 (not 1); DoD: unit test verifies stderr contains error + usage, exit code is 2, no network or tool exec attempted; CI and all gates green; one peer review completed.
* [ ] CLI version: add `--version`/`-version` to print semver + commit + build date and exit 0 without validating other flags; DoD: unit test asserts format and exit code; README “Usage” updated; CI and all gates green; one peer review completed.
* [ ] Reference docs: add `docs/reference/cli.md` that enumerates every flag with default, env fallback, precedence, and exit codes for `--help`/`--version`/missing-required; link from README; DoD: doc renders on GitHub, content matches current binary (checked by a small test that scans `--help` output for each documented flag), CI and all gates green; one peer review completed.
* [ ] Add CODEOWNERS at .github/CODEOWNERS to automatically request reviews from maintainers; smallest change is committing one CODEOWNERS file mapping paths to the maintainers team; scope repository hygiene; low risk; DoD includes PRs auto-requesting reviews from owners, tests unchanged and green with no coverage regression, all quality gates green, peer review completed; verify by opening a test pull request and observing requested reviewers; rollback by removing the CODEOWNERS file.
* [ ] Add SECURITY.md under .github with a concise vulnerability disclosure policy including contact, supported versions, and response expectations, and link it from README; smallest change is a single Markdown file and one README sentence; scope security documentation; low risk; DoD includes the GitHub Security tab surfacing the policy, tests unchanged and green with no coverage regression, all quality gates green, peer review completed; verify by visiting the repository Security page, rollback by removing the file and README link.
* [ ] Add pull request template at .github/PULL_REQUEST_TEMPLATE.md prompting for canonical issue URL, intent, Definition of Done checklist, and test plan; smallest change is committing one template file; scope contribution workflow; low risk; DoD includes new pull requests prefilled with the template, tests unchanged and green with no coverage regression, all quality gates green, peer review completed; verify by opening a draft pull request and seeing the template, rollback by removing the template file.
* [ ] Add issue templates at .github/ISSUE_TEMPLATE/bug_report.yml and .github/ISSUE_TEMPLATE/feature_request.yml plus config.yml to disable blank issues; smallest change is committing two minimal YAML templates and one config; scope issue hygiene; low risk; DoD includes the New issue page showing the templates with required fields, tests unchanged and green with no coverage regression, all quality gates green, peer review completed; verify by clicking New issue and observing the choices, rollback by removing the templates.
* [ ] Upload coverage profile and summary in CI by attaching bin/coverage.out as an artifact and printing total coverage using go tool cover func; smallest change is adding two steps in .github/workflows/ci.yml after the test step; scope CI; low risk; depends on the Makefile test target producing a coverage profile as already planned; DoD includes CI artifacts containing coverage.out and logs showing total coverage percentage, tests otherwise unchanged and green with no coverage regression, all quality gates green, peer review completed; verify by inspecting CI artifacts and logs, rollback by removing the new steps.
* [ ] Add GitHub CodeQL code scanning for Go by committing .github/workflows/codeql.yml using the official CodeQL action with default queries on push and pull_request so security analysis runs automatically; evidence: no CodeQL workflow exists today; scope .github/workflows only; low risk and independent; DoD: CodeQL job runs green with zero new alerts, tests unchanged and green with no coverage regression, all quality gates green (vet, gofmt, golangci-lint, staticcheck, security and secret detection) with no new findings, peer review completed; verify by viewing the Security > Code scanning alerts page and the workflow run logs; rollback by deleting the workflow file.
* [ ] Add jq to README Installation prerequisites with OS-specific install snippets (apt, brew, choco) because README examples and runbooks pipe tool output to jq but prerequisites omit it; smallest change is editing README only; scope documentation; low risk and independent; DoD: README renders correctly on GitHub, examples run from a clean clone with jq installed, tests unchanged and green with no coverage regression, all quality gates green, peer review completed; verify by executing one README example end-to-end with jq and observing the pretty-printed JSON; rollback by reverting the README edit.
* [ ] Add a primary CI workflow at .github/workflows/ci.yml that runs make tidy lint test build build-tools on a Go matrix (linux, macOS, windows) using actions/setup-go with go-version-file: go.mod and installs ripgrep where required; evidence: no workflows exist under .github/workflows; scope CI only; low risk and independent; DoD includes green runs on all OSes with all quality gates passing (vet, gofmt, golangci-lint, static analysis, security and secret detection), tests unchanged and green with race and coverage where configured, coverage artifacts uploaded when present, one peer review completed; verify by viewing successful workflow runs and artifacts in GitHub Actions; rollback by deleting ci.yml.
* [ ] Fix gofmt -s formatting drift by running make fmt and committing the resulting changes for the currently flagged files (e.g., cmd/agentcli/*.go, internal/oai/*.go, tools/cmd/fs_read_file/fs_read_file.go, tools/cmd/fs_write_file/fs_write_file.go) so fmtcheck is green; scope code formatting only; low risk and independent; DoD includes gofmt -s -l . returning no files, make fmtcheck and make lint passing locally and in CI, tests otherwise unchanged and green with no coverage regression, all quality gates green, one peer review completed; verify by running make fmtcheck; rollback by reverting the formatting commit.
* [ ] Set default temperature to 1.0 in `internal/llm/policy/defaults.go` (`DefaultCallPolicy.Temperature = 1.0`) with `top_p` unset; update CLI help in `cmd/cli/flags.go` to show “default: 1.0”; add unit test in `internal/llm/policy/defaults_test.go` asserting struct defaults; document in `docs/llm-policy.md` that OpenAI API defaults temperature to 1.0. ([OpenAI Platform][1], [OpenAI Community][2])
* [ ] Add model capability gate `SupportsTemperature` in `internal/llm/modelcaps/caps.go` with entries (e.g., `gpt-5: true`, any models that ignore/reject temperature: false) and expose `GetCaps(model string) ModelCaps`; write table-driven tests in `internal/llm/modelcaps/caps_test.go`; note that some reasoning models fix/ignore sampling knobs. ([Microsoft Learn][3], [OpenAI Community][4])
* [ ] Modify payload encoder in `internal/llm/client/payload.go` to omit `temperature` when `!caps.SupportsTemperature`, otherwise include policy value (1.0); add golden JSON tests in `internal/llm/client/payload_test.go` for both paths. ([OpenAI Platform][1])
* [ ] Implement parameter-recovery retry in `internal/llm/retry/parameter_recovery.go`: on HTTP 400 with message matching `unsupported|invalid parameter.*temperature`, drop `temperature` and retry once before backoff; integration test with mock server in `test/integration/mock_parameter_error_test.go`. ([OpenAI Platform][1])
* [ ] Enforce “change one knob” rule in `internal/llm/policy/sampling.go`: if user sets `--top-p`, unset temperature in payload (log a warning); if temperature is set (default 1.0), leave `top_p` nil; add tests in `internal/llm/policy/sampling_test.go`; document rationale in `docs/llm-policy.md`. ([Anthropic][5])
* [ ] Map profiles in `internal/llm/policy/derive.go`: `general→temperature=1.0`, `deterministic→temperature=0.1` only if supported, `creative→temperature=1.0`, `reasoning→temperature=1.0` (or omit if unsupported) and prefer reasoning-steering params; unit tests in `internal/llm/policy/derive_test.go`. ([Microsoft Learn][3], [OpenAI][6])
* [ ] Add GPT-5 smoke test `test/integration/providers/gpt5_defaults_test.sh` to run CLI with `--model gpt-5` and no flags, assert payload includes `temperature: 1` and accepts `verbosity`/`reasoning_effort`; document zero-config example in `docs/cli-usage.md`. ([OpenAI][6], [OpenAI Cookbook][7])
* [ ] Guard temperature-nudge logic in `internal/llm/policy/nudge.go` to no-op when `!SupportsTemperature` and clamp within `[0.1, 1.0]` otherwise; tests in `internal/llm/policy/nudge_test.go`. ([OpenAI Platform][1])
* [ ] Update docs `docs/llm-policy.md` to state default `temperature=1.0`, show GPT-5 `verbosity` (`low|medium|high`) and `reasoning_effort` usage, and call out that some reasoning models restrict sampling knobs; validate links in CI. ([OpenAI][6], [OpenAI Cookbook][7], [Microsoft Learn][3])
* [ ] Implement config precedence for temperature in `cmd/cli/flags.go`: `--temperature` > `LLM_TEMPERATURE` > config file > default 1.0, and if `--top-p` also provided then unset temperature with a CLI warning; add flag parsing tests in `cmd/cli/flags_test.go`. ([Anthropic][5])
* [ ] Append ADR addendum in `docs/adr/001-default-llm-policy.md` noting the change to temperature=1.0 by default for API parity and GPT-5 compatibility, with links to OpenAI docs; include concise rationale and rollout note. ([OpenAI Platform][1], [OpenAI][6])
* [ ] Emit observability fields `temperature_effective` and `temperature_in_payload` in `internal/llm/obs/log.go` to record defaults, omissions (unsupported), and user overrides; add unit tests in `internal/llm/obs/log_test.go`. ([OpenAI Platform][1])
* [ ] Extend contract tests in `test/contract/openai_mock_test.go` to assert: (1) default payload includes `temperature:1`, (2) excluded when `!SupportsTemperature`, (3) auto-retry without temperature on 400; make tests deterministic with a fake clock. ([OpenAI Platform][1])
* [ ] Create message validator `internal/llm/messages/validate.go` to reject any `role:"tool"` message lacking a preceding assistant message with `tool_calls[]` and a matching `tool_call_id`; add failing/then-passing tests in `internal/llm/messages/validate_test.go`. ([Microsoft Learn][8])
* [ ] Fix message assembly in `internal/llm/messages/build.go` to: after assistant returns `tool_calls[]`, append exactly one `role:"tool"` message per call with its `tool_call_id` and tool output, then re-query the model; add E2E mock test in `test/integration/tool_call_flow_test.go`. ([Microsoft Learn][8])
* [ ] Add regression test `internal/llm/messages/regression_toolcall_400_test.go` reproducing the exact API error where a stray `role:"tool"` appears without prior `tool_calls`; assert local validator blocks the request and surfaces a clear error. ([OpenAI Community][9])
* [ ] Document correct tool-call sequencing with a minimal JSON example in `README.md#tool-calls` (assistant with `tool_calls[]` → tool messages with matching `tool_call_id` → assistant), including note on parallel tool calls requiring one tool message per id. ([Microsoft Learn][8])
* [ ] Ensure parallel tool calls are supported by executing each `tool_calls[i]` concurrently and appending one `role:"tool"` message per returned `tool_call_id` before the next assistant call; add concurrency test `internal/llm/messages/parallel_tool_calls_test.go`. ([Microsoft Learn][8])
* [ ] Implement a **model capability map** in the internal request-options layer to determine `SupportsTemperature` per model (e.g., GPT-5 variants → true; any known exceptions → false with inline comment), expose a simple lookup used at call time, and write a table-driven unit test that covers at least three model IDs and both outcomes; DoD: lookup used by payload builder, tests green, brief note added to docs “Model parameter compatibility”.
* [ ] Update the **payload encoder** so that `temperature` is omitted entirely when `SupportsTemperature == false` and included (1.0 or user override) when true, preserving existing behavior for other params; add golden-file or snapshot tests for both branches; DoD: encoder tests green and logs confirm presence/omission in debug mode.
* [ ] Add **parameter-recovery retry**: if the API returns HTTP 400 with a message indicating an invalid/unsupported `temperature`, strip the parameter and retry once before the normal exponential backoff path, with a structured log field describing the recovery; DoD: integration test with a mock server that first 400s on `temperature` and then succeeds without it, logs verified.
* [ ] Enforce **“change one sampling knob”**: when user passes `--top-p`, ensure the payload does not include `temperature`; when `--top-p` is unset, send `temperature` (default 1.0) and leave `top_p` null; add unit tests for precedence and serialization, and add a one-sentence rule to docs; DoD: tests green, docs updated.
* [ ] Implement a **prompt profile mapper** (deterministic | general | creative | reasoning) that sets temperature as follows: deterministic→0.1 (only if supported), general→1.0, creative→1.0, reasoning→1.0 unless model forbids it (then omit); add unit tests for profile→option mapping and a doc table with examples; DoD: mapper covered by tests, docs updated.
* [ ] Add a **smoke test path for GPT-5** in integration tests using a mock OpenAI-compatible endpoint: assert the request includes `temperature: 1` by default and that additional reasoning controls (e.g., verbosity/effort if you support them) can be set while keeping temperature at 1; DoD: test green and instructions in docs “Zero-config with GPT-5”.
* [ ] Extend **temperature-nudge logic** to no-op when `SupportsTemperature == false` and to clamp within \[0.1, 1.0] otherwise; include unit tests that simulate repetition/format-failure signals to trigger −0.1 adjustments and diversity signals to +0.1 (never exceeding 1.0); DoD: tests green and brief docs note.
* [ ] Add **observability fields** `temperature_effective` (the value actually used after clamps/omissions) and `temperature_in_payload` (bool) to structured logs, and document them in the troubleshooting section; DoD: unit test asserts both fields are emitted, docs updated.
* [ ] Keep agent loop safety by verifying **`-max-steps` defaults to 8** (hard wall 15 in code if not already present), and add a unit test that the loop terminates with a clear “needs human review” message when the cap is hit; DoD: tests green and README mentions the guard. ([GitHub][1])
* [ ] Implement a **message-sequence validator** that rejects any `role:"tool"` message unless it responds to a prior assistant message with `tool_calls[]` and a matching `tool_call_id`, and surface a pre-flight error that mirrors the API’s wording; add unit tests for valid/invalid transcripts; DoD: validator on by default, tests green, troubleshooting doc updated. ([OpenAI Platform][2])
* [ ] Fix **message assembly** so the flow is always: user/assistant→assistant with `tool_calls[]`→one `tool` message per `tool_call_id` with the tool output→assistant (repeat as needed), never emitting a standalone `tool` message early; add an end-to-end mock test that exercises one and multiple tool calls; DoD: test green and README shows a minimal JSON example of correct sequencing. ([OpenAI Platform][2])
* [ ] Add **parallel tool-call support**: execute multiple `tool_calls[]` concurrently and append exactly one `tool` message per returned `tool_call_id` in any order acceptable to the API, then continue; include a concurrency unit test that simulates two tools with different latencies; DoD: tests green and docs example added.
* [ ] Add **length backoff**: when the API reply indicates truncation (e.g., `finish_reason == "length"` or provider-equivalent), automatically double the completion cap once (bounded by remaining context) and retry; include unit tests that simulate truncation; DoD: tests green and behavior documented.
* [ ] Ensure **HTTP timeouts and retries** align with your README flags (`-http-timeout`, `-http-retries`, `-http-retry-backoff`) by wiring jittered exponential backoff for 429/5xx/timeouts and keeping the global default timeout sane (e.g., minutes, not seconds); add unit tests for retry schedule and a doc snippet clarifying defaults; DoD: tests green and README consistent. ([GitHub][1])
* [ ] Update **README “Common flags”** so all listed defaults (especially `-temp 1.0` and `-max-steps 8`) match the executable’s behavior, and add a short “Why you usually don’t need to change knobs” section pointing to the policy; DoD: README committed and links from the table of contents work. ([GitHub][1])
* [ ] Add an **ADR (“Default LLM Call Policy”)** under `docs/` (create `docs/adr` if missing) capturing context, options considered, the decision to default temperature to 1.0 with capability-based omission, and the retry/guard policies; include a Mermaid sequence of the tool-call flow; DoD: ADR merged and diagram renders on GitHub.
* [ ] Provide a **worked example** in `examples/` demonstrating a tool-call session that exercises: default temperature 1.0, parallel tool calls, and the corrected message sequencing; include a tiny fake tool and a transcript dump; DoD: `go test ./examples/...` (or your repo’s test convention) passes and README links to it.
* [ ] Add a **regression test for the exact 400** you hit by crafting a transcript with a stray `role:"tool"` lacking a prior `tool_calls[]`; assert the validator blocks it locally with a helpful error and that the request is never sent; DoD: failing test first, then fix, then green, and an entry added to the Troubleshooting section.
