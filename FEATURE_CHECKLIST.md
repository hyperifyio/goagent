* [x] Fix errcheck warnings by handling or asserting error returns in tests currently flagged by golangci-lint (e.g., internal/oai/client_test.go writes and cmd/agentcli/main_test.go json Encode/Setenv/Unsetenv), smallest change is editing only those tests to check errors or add narrowly justified nolint comments, scope lint hygiene (tests only), low risk, DoD includes `make lint` passing with errcheck clean and tests unchanged and green with no coverage regression, all quality gates green, peer review completed, verification by running `make lint` and observing no errcheck diagnostics in those files, rollback by reverting the test edits.
* [x] Remove the inadvertently committed root-level `agentcli` binary and prevent reintroduction by adding `agentcli` (and Windows `agentcli.exe`) to `.gitignore`; smallest change is `git rm agentcli` and appending two ignore entries; scope repository hygiene; low risk; DoD includes `git ls-files --error-unmatch agentcli` failing, `make build` producing `bin/agentcli` as documented, `git status` clean after builds across OSes, tests unchanged and green with no coverage regression, all quality gates green, peer review completed; verification by running those commands; rollback by reverting the `.gitignore` edit and restoring the file if necessary.
* [x] Remove tracked lint artifacts `lint.err` and `lint_verify.err` and add ignore entries for them in `.gitignore` to keep the working tree clean after lint runs; smallest change is `git rm` those files and append two ignore lines; scope repository hygiene; low risk; DoD includes `git status` clean after `make lint`, tests unchanged and green with no coverage regression, all quality gates green, peer review completed; verification by running `make lint` and observing no new tracked `*.err` files; rollback by reverting the `.gitignore` edit and re-adding the files if required.
* [x] Fix errcheck warnings in production code by handling or asserting error returns currently flagged in non-test packages (e.g., cmd/agentcli/main.go writePrepCache calls, internal/oai/client.go resp.Body.Close/io.ReadAll, tools/cmd/img_create/*.go Encode/Close/Remove); smallest change is adding error checks or narrowly justified ignores where safe; scope limited to non-test packages and tool binaries; low risk and independent; DoD includes make lint passing with no errcheck diagnostics in these files, tests unchanged and green with no coverage regression, all quality gates green; verify by running make lint and confirming errcheck clean; rollback by reverting the edits.
* [x] Reduce cyclomatic complexity of tools/cmd/img_create/img_create.go function run (gocyclo=54) by extracting small helpers for input parse/validate, API request/response handling, file writes, and stdout JSON; no behavior change; scope single tool; low–moderate effort; DoD includes golangci-lint gocyclo no longer flagging run (>20), make lint and tests passing, coverage unchanged, peer review completed; verify via golangci-lint output and go test; rollback by reverting the refactor.
* [x] Reduce cyclomatic complexity of internal/tools/runner.RunToolWithJSON (gocyclo=21) by extracting environment construction and process execution into focused helpers without changing semantics; scope internal/tools only; low effort and independent; DoD includes golangci-lint gocyclo clean for this function, make lint and tests passing, coverage unchanged; verify via golangci-lint and go test; rollback by reverting the refactor.
* [x] Remove the staticcheck SA9003 empty branch in cmd/agentcli/main.go around the pre-stage block (~line 673) by deleting the no-op branch or consolidating logic; scope single file; low risk and independent; DoD includes make lint passing with no SA9003 warning, tests green with no coverage regression, all quality gates green; verify by rerunning make lint and confirming staticcheck clean; rollback by reverting the line-level change.
* [x] Ignore editor swap files and remove the stray .FEATURE_CHECKLIST.md.swp: append a *.swp entry to .gitignore (minimal change) and delete the existing file; scope repository hygiene; low risk and independent; DoD includes git status clean after editing with Vim (no new tracked *.swp), git ls-files --error-unmatch .FEATURE_CHECKLIST.md.swp fails, tests and lint unchanged and green with no coverage regression, all quality gates green; verify by creating and saving a file in Vim and observing no tracked swap file; rollback by reverting the .gitignore edit and restoring the file if necessary.
* [x] Correct the README fs_search example to match the tool schema: replace invalid keys (path, pattern, glob, caseInsensitive) with query (string), globs (array of file globs), and regex (boolean), and remove path since fs_search scans the repository root; smallest change is editing README only; scope documentation; low risk and independent; DoD includes the updated example running successfully on a clean clone (producing expected matches), tests and lint unchanged and green with no coverage regression, all quality gates green; verify by running the example exactly as shown; rollback by reverting the README edit.
* [x] **Tool: http_fetch (safe HTTP/HTTPS fetcher)** — File `tools/cmd/http_fetch/http_fetch.go`; **stdin** `{"url":string,"method?":"GET|HEAD","max_bytes?":1048576,"timeout_ms?":10000,"decompress?":true}`, **stdout** `{"status":int,"headers":object,"body_base64?":string,"truncated":bool}`; allow only http/https, stream with hard **byte cap**, ≤5 redirects, preserve `ETag/Last-Modified`, **SSRF guard** as above, UA `agentcli-http-fetch/0.1`; **env** optional `HTTP_TIMEOUT_MS`; **errors** stderr JSON; **audit** `{tool:"http_fetch",url_host,status,bytes,truncated,ms}`; **manifest** add entry with schema and `envPassthrough:["HTTP_TIMEOUT_MS"]`; **Makefile** add to `TOOLS`; **tests** redirects, gzip body, truncation, SSRF block, HEAD; **docs** ref page; **DoD:** build, tests, lint, capabilities OK, docs render.
* [x] **ADR-0010: Adopt SearXNG & network research toolbelt (CLI-only)** — Add `docs/adr/0010-research-tools-searxng.md` describing context (need credible web discovery + provenance), options (direct engine APIs vs meta-search vs scraping), **decision** (SearXNG + small CLI subtools), consequences (operate with SSRF guard, robots respect, retries), and a Mermaid flow (agentcli→tool_calls→fetch/parse→citation); link from `README.md` and `docs/README.md`; **DoD:** file renders on GitHub with diagram, links resolve, no code changes, `make lint test` green.
* [x] **Tool: searxng_search (meta search over the web)** — We have SarxNG running at http://localhost:8888. Create `tools/cmd/searxng_search/searxng_search.go` → `tools/bin/searxng_search(.exe)`; **stdin** `{"q":string,"time_range?":"day|week|month|year","categories?":[string],"engines?":[string],"language?":string,"page?":int,"size?":int<=50}`, **stdout** `{"query":string,"results":[{"title":string,"url":string,"snippet":string,"engine":string,"published_at?":string}]}`; GET `${SEARXNG_BASE_URL}/search?format=json&q=...` with 10s timeout, ≤5 redirects, **retries** 2 on timeout/429/5xx (respect `Retry-After`), **SSRF guard** (block loopback/RFC1918/link-local/IPv6 ::1 & DNS-rebinding), UA `agentcli-searxng/0.1`; **env** required `SEARXNG_BASE_URL`, optional `HTTP_TIMEOUT_MS`; **errors**: single-line stderr JSON `{"error":"...","hint?":"..."}` + exit≠0; **audit** append NDJSON `{ts,tool:"searxng_search",url_host,query,status,ms,retries}` under `.goagent/audit/YYYYMMDD.log` (redact query if >256 chars → `query_truncated:true`); **manifest**: append to root `tools.json` `"name":"searxng_search","description":"Meta search via SearXNG","schema":<stdin JSON Schema>,"command":["./tools/bin/searxng_search"],"timeoutSec":15,"envPassthrough":["SEARXNG_BASE_URL","HTTP_TIMEOUT_MS"]` (Windows uses `.exe`); **Makefile**: add to `TOOLS += searxng_search`; **tests**: offline using `httptest.Server` fixtures for success, 429 with `Retry-After`, 5xx then success, SSRF blocked, bad base URL; **docs**: `docs/reference/searxng_search.md` with examples; **DoD:** `make build-tools` produces binary, `go test ./...` & `make lint` green, `agentcli -capabilities` lists tool, docs render.
* [x] **Tool: robots_check (robots.txt evaluator)** — `tools/cmd/robots_check/robots_check.go`; **stdin** `{"url":string,"user_agent?":"agentcli"}`, **stdout** `{"allowed":bool,"crawl_delay_ms?":int,"group_rules":[string]}`; fetch `<origin>/robots.txt` with internal safe GET (5s), RFC 9309 precedence (UA-specific then `*`), no redirects to non-origin, cache in-process for test, **SSRF guard** applies; **env** none; **errors** stderr JSON; **audit** `{tool:"robots_check",origin,allowed,ms}`; **manifest** add entry; **Makefile** add; **tests** fixtures covering allow/deny precedence, UA match, Crawl-delay; **docs** page with examples; **DoD:** build/tests/lint green, doc render.
* [x] **Tool: readability_extract (article extraction)** — `tools/cmd/readability_extract/readability_extract.go`; **stdin** `{"html":string,"base_url":string}` (≤5 MiB), **stdout** `{"title":string,"byline?":string,"text":string,"content_html":string,"length":int}` using `github.com/go-shiori/go-readability`; **env** none; **errors** stderr JSON; **audit** `{tool:"readability_extract",length,ms}`; **manifest** add entry; **Makefile** add; **tests** article vs nav-heavy fixtures, large HTML rejected; **docs** page; **DoD:** build/tests/lint green, docs render.
* [x] **Tool: metadata_extract (OG/Twitter/JSON-LD)** — `tools/cmd/metadata_extract/metadata_extract.go`; **stdin** `{"html":string,"base_url":string}`, **stdout** `{"opengraph":object,"twitter":object,"jsonld":[any]}`; **errors/audit/manifest/Makefile/docs/tests** similar pattern; **tests** cover all three metadata types; **DoD:** build/tests/lint green, docs render.
* [x] **Tool: pdf_extract (PDF text, optional OCR)** — `tools/cmd/pdf_extract/pdf_extract.go`; **stdin** `{"pdf_base64":string,"pages?":[int]}` (≤20 MiB), **stdout** `{"page_count":int,"pages":[{"index":int,"text":string}]}` via `github.com/ledongthuc/pdf`; if `ENABLE_OCR=true` and page is image-only, shell to `tesseract` (if absent emit stderr JSON `"OCR_UNAVAILABLE"`), 10s/page cap; **SSRF** N/A; **audit** `{tool:"pdf_extract",page_count,ms}`; **manifest** include `envPassthrough:["ENABLE_OCR"]`; **Makefile** add; **tests** normal text PDF, image-only PDF without OCR, with OCR (mock), oversize rejects; **docs**; **DoD:** build/tests/lint green, docs render.
* [x] **Tool: rss_fetch (RSS/Atom)** — `tools/cmd/rss_fetch/rss_fetch.go`; **stdin** `{"url":string,"if_modified_since?":string}`, **stdout** `{"feed":{"title":string,"link":string},"items":[{"title":string,"url":string,"published_at?":string,"summary?":string}]}`; conditional GET (pass If-Modified-Since), 5s timeout, **SSRF guard**; **errors/audit/manifest/Makefile/docs/tests**; **tests** RSS, Atom, 304 path; **DoD:** build/tests/lint green, docs render.
* [x] **Tool: wayback_lookup (Internet Archive)** — `tools/cmd/wayback_lookup/wayback_lookup.go`; **stdin** `{"url":string,"save?":false}`, **stdout** `{"closest_url?":string,"timestamp?":string,"saved?":bool}`; call `https://web.archive.org/save/` when `save=true` and `.../available?url=...` for lookup, 3s timeout, 1 retry w/ jitter on 5xx; **audit** `{tool:"wayback_lookup",saved:boolean,ms}`; **manifest/Makefile/docs/tests**; **DoD:** build/tests/lint green, docs render.
* [x] **Tool: wiki_query (MediaWiki summaries/search)** — `tools/cmd/wiki_query/wiki_query.go`; **stdin** `{"titles?":string,"search?":string,"language?":"en"}`, **stdout** `{"pages":[{"title":string,"url":string,"extract":string}]}`; call MediaWiki action API extracts/opensearch per input, 5s timeout, language fallback to `"en"` if miss; **errors/audit/manifest/Makefile/docs/tests**; **DoD:** build/tests/lint green, docs render.
* [x] **Tool: openalex_search (scholarly works)** — `tools/cmd/openalex_search/openalex_search.go`; **stdin** `{"q":string,"from?":string,"to?":string,"per_page?":10}`, **stdout** `{"results":[{"title":string,"doi?":string,"publication_year":int,"open_access_url?":string,"authorships":[...],"cited_by_count":int}],"next_cursor?":string}`; GET `https://api.openalex.org/works?...` (no key), 8s timeout, retries 1; **audit/manifest/Makefile/docs/tests**; **DoD:** build/tests/lint green.
* [x] **Tool: crossref_search (DOI metadata)** — `tools/cmd/crossref_search/crossref_search.go`; **stdin** `{"q":string,"rows?":10}`, **stdout** `{"results":[{"title":string,"doi":string,"issued":string,"container":string,"title_short?":string}]}`; require `CROSSREF_MAILTO` (send polite header), 8s timeout; **audit/manifest (envPassthrough:["CROSSREF_MAILTO"])/Makefile/docs/tests** including quota handling; **DoD:** build/tests/lint green.
* [x] **Tool: github_search (repos/code/issues/commits)** — `tools/cmd/github_search/github_search.go`; **stdin** `{"q":string,"type":"repositories|code|issues|commits","per_page?":10}`, **stdout** `{"results":[...minimal per type...],"rate":{"remaining":int,"reset":int}}`; optional `GITHUB_TOKEN` (bearer), inspect `X-RateLimit-Remaining`, map 0 to stderr JSON `{"error":"RATE_LIMITED","hint":"use GITHUB_TOKEN"}`; 8s timeout, 1 retry on 5xx; **audit/manifest (envPassthrough:["GITHUB_TOKEN"])/Makefile/docs/tests**; **DoD:** build/tests/lint green.
* [x] **Tool: dedupe_rank (near-duplicate detector)** — `tools/cmd/dedupe_rank/dedupe_rank.go`; **stdin** `{"docs":[{"id":string,"url?":string,"title?":string,"text?":string,"published_at?":string}]}`, **stdout** `{"groups":[{"representative_id":string,"members":[string],"score":number}]}`; MinHash (3-shingles) + TF-IDF tie-break; optional `AUTHORITY_HINTS_JSON` to bias ranking; **errors/audit/manifest/Makefile/docs/tests** with deterministic golden; **DoD:** build/tests/lint green.
* [ ] **Tool: citation_pack (normalize + archive)** — `tools/cmd/citation_pack/citation_pack.go`; **stdin** `{"doc":{"title?":string,"url":string,"published_at?":string},"archive?":{"wayback?":bool}}`, **stdout** `{"title?":string,"url":string,"host":string,"accessed_at":string,"archive_url?":string}`; if `archive.wayback`, call Wayback lookup (3s), otherwise skip network; **errors/audit/manifest/Makefile/docs/tests**; **DoD:** build/tests/lint green.
* [ ] **Reference & contracts (single page for all research tools)** — Add `docs/reference/research-tools.md` enumerating **each tool’s** stdin/out JSON, required envs, exit codes (0 ok; non-zero with stderr JSON), SSRF/timeout/retry rules, and copy-paste examples; link from main README; **DoD:** page renders with anchors to all tools; `make lint` green.
* [ ] **Security posture for research tools** — Add `docs/security/research-tools.md` detailing SSRF allowlist/denylist (block loopback, RFC1918/4193, link-local, `.onion`), robots compliance expectations, outbound UA strings, audit NDJSON fields and **redaction policy**, and guidance for sandboxing tools when used with untrusted prompts; link from `docs/security/threat-model.md`; **DoD:** page renders, links resolve, `make lint` green.
* [ ] **Research pipeline diagram** — Add `docs/diagrams/research-pipeline.md` (Mermaid `flowchart`) showing `agentcli → tool_calls → (searxng_search → http_fetch → readability/metadata/pdf/rss) → dedupe_rank → citation_pack → assistant(final)`; link from ADR-0010 and `docs/README.md`; **DoD:** diagram renders on GitHub; links resolve.
* [ ] **Runbook: troubleshooting research tools** — Extend `docs/runbooks/troubleshooting.md` with a new section covering: missing envs (`SEARXNG_BASE_URL`, `CROSSREF_MAILTO`), SSRF block messages, 429 with `Retry-After` handling, robots disallow, response truncation (`max_bytes`), and network timeouts (raising `HTTP_TIMEOUT_MS`); **DoD:** content renders; `rg` finds section header; lint green.
* [ ] **Examples (manual, no agent)** — Add `examples/research/README.md` with commands like `echo '{"q":"golang"}' | ./tools/bin/searxng_search` and `echo '{"url":"https://..." }' | ./tools/bin/http_fetch | jq .status`, plus a **fixtures-only** test command pinned to `httptest.Server` scripts (commented to avoid network in CI); **DoD:** examples render; no CI network usage.
* [ ] **Makefile wiring per tool** — For each tool you implement, append its name to `TOOLS += ...`, ensure `make build-tools` emits `tools/bin/<name>(.exe)` with `-trimpath` and deterministic flags, ensure `make clean` removes it; **DoD:** running `make build-tools clean` leaves `git status` clean, build repeatable (same shasum across two builds).
* [ ] Add a link to the main README.md about following the project by following the author at Linkedin (https://www.linkedin.com/in/jheusala/)
